{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "relative_path = 'data/compressed_preprocessed.pbz2'\n",
    "frame_path = current_dir.joinpath(relative_path)\n",
    "df = bz2.BZ2File(str(frame_path), 'rb')\n",
    "df = cPickle.load(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_df(name):\n",
    "#     current_dir = Path.cwd()\n",
    "#     relative_path = 'data/preprocessed_' + name + '.pbz2'\n",
    "#     frame_path = current_dir.joinpath(relative_path)\n",
    "#     df = bz2.BZ2File(str(frame_path), 'rb')\n",
    "#     df = cPickle.load(df)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_map = {'x_train': X_train, 'x_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "# X_train = load_df('x_train')\n",
    "# X_test = load_df('x_test')\n",
    "# y_train = load_df('y_train')\n",
    "# y_test = load_df('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_goal']\n",
    "X = df.drop(labels=['is_goal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=df['is_goal'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_prob(y):\n",
    "    return sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Probability of goal in sample: {goal_prob(y):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, df_scores, clf_name=None):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    if clf_name is None:\n",
    "        if isinstance(clf, Pipeline):\n",
    "            clf_name = clf[-1].__class__.__name__\n",
    "        else:\n",
    "            clf_name = clf.__class__.__name__\n",
    "    acc = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    bal_acc = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    "    prec_score = metrics.precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall_score = metrics.recall_score(y_test, y_pred)\n",
    "    clf_score = pd.DataFrame(\n",
    "        {clf_name: [acc, bal_acc, f1_score, prec_score, recall_score]},\n",
    "        index=['Accuracy', 'Balanced accuracy', 'F1 score', 'Precision', 'Recall']\n",
    "    )\n",
    "    df_scores = pd.concat([df_scores, clf_score], axis=1).round(decimals=3)\n",
    "    return df_scores\n",
    "\n",
    "df_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_mostfreq_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "df_scores = evaluate_classifier(dummy_mostfreq_clf, df_scores, \"Dummy (Most Frequent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_strat_clf = DummyClassifier(strategy=\"stratified\", random_state=0)\n",
    "df_scores = evaluate_classifier(dummy_strat_clf, df_scores, \"Dummy (Stratified)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_iterations=400\n",
    "param_grid = [ {'class_weight': [None, 'balanced'],\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 100]} ]\n",
    "clf = GridSearchCV(\n",
    "    LogisticRegression(max_iter=lr_iterations), param_grid, scoring='balanced_accuracy'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "C = clf.best_params_['C']\n",
    "class_weight = clf.best_params_['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_iterations=1000\n",
    "lr_clf = make_pipeline(\n",
    "    LogisticRegression(max_iter=lr_iterations, C=C, class_weight=class_weight)\n",
    ")\n",
    "df_scores = evaluate_classifier(lr_clf, df_scores, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = make_pipeline(\n",
    "    RandomForestClassifier(random_state=0, n_jobs=2)\n",
    ")\n",
    "df_scores = evaluate_classifier(rf_clf, df_scores, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_iterations=1000\n",
    "param_grid = [ {'class_weight': [None, 'balanced'],\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 1]} ]\n",
    "clf = GridSearchCV(\n",
    "    LinearSVC(random_state=0, tol=1e-5, max_iter=svm_iterations, dual=False), param_grid, scoring='balanced_accuracy'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "C = clf.best_params_['C']\n",
    "class_weight = clf.best_params_['class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = make_pipeline(\n",
    "    LinearSVC(random_state=0, tol=1e-5, max_iter=svm_iterations, dual=False, C=C, class_weight=class_weight)\n",
    ")\n",
    "df_scores = evaluate_classifier(svm_clf, df_scores, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\n",
    "df_scores = evaluate_classifier(\n",
    "    rf_clf, df_scores, \"RF with class weight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = make_pipeline_with_sampler(\n",
    "    RandomUnderSampler(random_state=0),\n",
    "    LogisticRegression(max_iter=lr_iterations)\n",
    ")\n",
    "df_scores = evaluate_classifier(\n",
    "    lr_clf, df_scores, \"LR with under-sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = make_pipeline_with_sampler(\n",
    "    RandomUnderSampler(random_state=0),\n",
    "    RandomForestClassifier(random_state=0, n_jobs=2)\n",
    ")\n",
    "\n",
    "df_scores = evaluate_classifier(\n",
    "    rf_clf, df_scores, \"RF with under-sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = make_pipeline_with_sampler(\n",
    "    RandomUnderSampler(random_state=0),\n",
    "    LinearSVC(random_state=0, tol=1e-5, max_iter=svm_iterations, dual=False)\n",
    ")\n",
    "\n",
    "df_scores = evaluate_classifier(\n",
    "    svm_clf, df_scores, \"SVM with under-sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = make_pipeline(\n",
    "    BalancedRandomForestClassifier(random_state=0, n_jobs=2)\n",
    ")\n",
    "\n",
    "df_scores = evaluate_classifier(rf_clf, df_scores, \"Balanced RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,30,5):\n",
    "    print(f\"Evaluating n = {i}\")\n",
    "    bag_clf = make_pipeline(\n",
    "        BalancedBaggingClassifier(\n",
    "            base_estimator=HistGradientBoostingClassifier(random_state=0),\n",
    "            n_estimators=i, random_state=0, n_jobs=2\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    t = \"Balanced bagging (n=\" + str(i) + \")\"\n",
    "    df_scores = evaluate_classifier(\n",
    "        bag_clf, df_scores, t\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,300,50):\n",
    "    print(f\"Evaluating n = {i}\")\n",
    "    rus_clf = make_pipeline(\n",
    "        RUSBoostClassifier(n_estimators=i, algorithm='SAMME.R', random_state=0)\n",
    "    )\n",
    "    \n",
    "    t = \"RUSBoost (n=\" + str(i) + \")\"\n",
    "    df_scores = evaluate_classifier(\n",
    "        rus_clf, df_scores, t\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_clf = make_pipeline(\n",
    "    EasyEnsembleClassifier(random_state=0)\n",
    ")\n",
    "\n",
    "df_scores = evaluate_classifier(\n",
    "    eec_clf, df_scores, \"EEC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
